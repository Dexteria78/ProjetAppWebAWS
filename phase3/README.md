# Phase 3 - Haute Disponibilit√© et Scalabilit√©

## üìã Objectif

Impl√©menter une architecture hautement disponible et scalable avec un VPC d√©di√©, un Application Load Balancer et un Auto Scaling Group pour distribuer la charge sur plusieurs instances dans plusieurs zones de disponibilit√©.

## üéØ Exigences Phase 3

- ‚úÖ Lancer un √©quilibreur de charge (ALB)
- ‚úÖ Cr√©er un Launch Template pour les instances EC2
- ‚úÖ Mettre en place un Auto Scaling Group multi-AZ
- ‚úÖ Tester l'application (affichage, ajout, suppression, modification)
- ‚úÖ Effectuer un test de charge pour v√©rifier le scaling automatique

---

## üèóÔ∏è Architecture

![Architecture Phase 3](architecture-phase3.png)

## üì¶ Composants D√©ploy√©s

### VPC & R√©seau
| Ressource | Valeur |
|-----------|--------|
| VPC CIDR | 10.0.0.0/16 |
| Public Subnet 1 | 10.0.1.0/24 (us-east-1a) |
| Public Subnet 2 | 10.0.4.0/24 (us-east-1b) |
| Private Subnet 1 | 10.0.2.0/24 (us-east-1a) - RDS |
| Private Subnet 2 | 10.0.3.0/24 (us-east-1b) - RDS |
| Internet Gateway | Acc√®s Internet pour subnets publics |

### Application Load Balancer
| Param√®tre | Valeur |
|-----------|--------|
| Type | Application (Layer 7) |
| Scheme | Internet-facing |
| Listener | HTTP port 80 |
| Health check path | `/` |
| Healthy threshold | 2 checks |
| Unhealthy threshold | 2 checks |
| Health check interval | 30s |
| Health check timeout | 5s |

### Auto Scaling Group
| Param√®tre | Valeur |
|-----------|--------|
| Min instances | 2 |
| Max instances | 5 |
| Desired capacity | 2 |
| AZ | us-east-1a + us-east-1b |
| Health check type | ELB |
| Health check grace period | 300s |

### Launch Template
| Param√®tre | Valeur |
|-----------|--------|
| AMI | Ubuntu 22.04 LTS (latest) |
| Instance type | t2.micro |
| Volume | 20 GB gp3 |
| IAM Profile | LabInstanceProfile |

### Scaling Policies (Target Tracking)
| Policy | Metric | Target |
|--------|--------|--------|
| CPU Tracking | ASGAverageCPUUtilization | 70% |
| Request Tracking | ALBRequestCountPerTarget | 1000 req/target |

### RDS MySQL
| Param√®tre | Valeur |
|-----------|--------|
| Engine | MySQL 8.0 |
| Instance | db.t3.micro |
| Storage | 20 GB gp3 |
| Multi-AZ | Non (co√ªt) |
| Backup | D√©sactiv√© (d√©veloppement) |
| Public access | Non |

### Autres Composants
- **AWS Secrets Manager** : `student-records-app-db-credentials-phase3`
- **AWS Cloud9** : Environnement t3.small pour administration (auto-stop 30 min)

## üîß Choix Techniques

### VPC d√©di√© vs VPC par d√©faut
Phase 3 cr√©e un **VPC d√©di√©** pour une isolation r√©seau compl√®te :
- Contr√¥le total du plan d'adressage
- S√©paration publique/priv√©e des ressources
- Pr√©paration pour une architecture de production

### Dual Scaling Policies
Deux politiques de scaling compl√©mentaires :
1. **CPU-based** : R√©agit √† la charge CPU des instances
2. **Request Count-based** : R√©agit directement au volume de requ√™tes HTTP

### EC2 dans subnets publics
Les instances EC2 sont dans les subnets publics pour simplifier le d√©ploiement (pas de NAT Gateway n√©cessaire), tout en √©tant prot√©g√©es par Security Groups.

### RDS dans subnets priv√©s
La base de donn√©es est enti√®rement isol√©e dans des subnets priv√©s sans acc√®s Internet.

## üìä Fichiers Terraform

```
phase3/
 terraform.tf       # Provider AWS + version
 variables.tf       # Variables (CIDR, types, etc.)
 network.tf         # VPC, subnets, IGW, route tables
 security.tf        # Security Groups (ALB, web, RDS)
 loadbalancer.tf    # ALB, Target Group, Listener
 launch-template.tf # Template EC2 pour ASG
 autoscaling.tf     # ASG + scaling policies
 database.tf        # RDS MySQL + subnet group
 secrets.tf         # Secrets Manager
 app-secret.tf      # Secret pour l'application
 cloud9.tf          # Environnement Cloud9
 data.tf            # Data sources (AMI, IAM)
 outputs.tf         # Outputs (ALB URL, RDS endpoint...)
 userdata.sh        # Bootstrap EC2 instances
```

## 
```bash
# 1. Aller dans le dossier phase3
cd phase3

# 2. Initialiser Terraform
terraform init

# 3. V√©rifier le plan
terraform plan

# 4. Appliquer
terraform apply -auto-approve

# 5. R√©cup√©rer l'URL de l'application
terraform output application_url
```

### Temps de d√©ploiement estim√©
- VPC + r√©seau : ~30 secondes
- Security Groups : ~10 secondes
- ALB + Target Group : ~30 secondes
- RDS MySQL : ~8-10 minutes
- EC2 instances (via ASG) : ~3 minutes
- **Total : ~12-15 minutes**

## ‚úÖ Tests Effectu√©s

### Test fonctionnel
```bash
# Page d'accueil
curl http://<ALB-DNS-NAME>/

# Liste des √©tudiants
curl http://<ALB-DNS-NAME>/students

# Ajout, modification, suppression via l'interface web
```

### Test de charge (loadtest)
```bash
npm install -g loadtest

# Test avec 100 utilisateurs simultan√©s pendant 60 secondes
loadtest -c 100 -t 60 http://<ALB-DNS-NAME>/students

# R√©sultats observ√©s :
# - CPU monte au-dessus de 70%
# - ASG d√©clenche scale-out automatiquement
# - Nouvelles instances int√©gr√©es dans ~3 minutes
# - CPU redescend, scale-in apr√®s cooldown
```

## üöß Difficult√©s Rencontr√©es

1. **Timing EC2 vs RDS**
   - **Probl√®me** : Les instances EC2 d√©marraient avant que RDS soit disponible
   - **Solution** : `depends_on = [aws_db_instance.main, aws_secretsmanager_secret_version...]` dans l'ASG

2. **Health checks √©chouaient au d√©marrage**
   - **Probl√®me** : L'application Node.js prenait du temps √† d√©marrer
   - **Solution** : Grace period de 300s + seuil de 2 checks seulement

3. **Subnets publics pour ASG**
   - **Observation** : Pas de NAT Gateway (co√ªt), donc EC2 dans subnets publics
   - **Implication** : Les instances ont des IPs publiques mais sont prot√©g√©es par SG

4. **CIDR overlap**
   - **Probl√®me** : Chevauchement initial entre subnets publics et priv√©s
   - **Solution** : Plan CIDR pr√©cis (public: .1.x, .4.x / priv√©: .2.x, .3.x)

## üìà M√©triques

| M√©trique | Valeur |
|----------|--------|
| Latence moyenne (2 instances) | ~100ms |
| Throughput max (2 instances) | ~150 req/s |
| Temps scale-out | ~3 minutes |
| Min instances | 2 (haute disponibilit√©) |
| Max instances | 5 |

### Co√ªts estim√©s (us-east-1)
| Ressource | Co√ªt/mois |
|-----------|-----------|
| ALB | ~$16 |
| EC2 2x t2.micro | ~$17 |
| RDS db.t3.micro | ~$12 |
| Data Transfer | ~$2 |
| Secrets Manager | ~$0.40 |
| Cloud9 (30min/j) | ~$1 |
| **Total** | **~$48/mois** |

## üîí S√©curit√©

### Security Groups en cascade
```
Internet ‚Üí ALB-SG (port 80)
            ‚Üì
         Web-SG (port 80 depuis ALB-SG uniquement)
            ‚Üì
         RDS-SG (port 3306 depuis Web-SG uniquement)
```

### Isolation RDS
- Subnets priv√©s, pas d'IP publique
- Accessible uniquement depuis les instances EC2
- Chiffrement possible au repos

### Secrets Manager
- Secret `student-records-app-db-credentials-phase3`
- JSON avec `username`, `password`, `host`, `dbname`
- R√©cup√©r√© dynamiquement au d√©marrage des instances

## üßπ Nettoyage

```bash
terraform destroy -auto-approve
```

 Prochaines √âtapes (Phase 4)## 

- Conteneurisation de l'application avec Docker
- Stockage de l'image sur Amazon ECR
- D√©ploiement du container sur EC2

## üé• Vid√©os de d√©monstration

Les vid√©os de d√©ploiement et de test sont disponibles sur **MyDrive** :
[https://drive.google.com/drive/folders/1698wO-jPW8hJ28d3EpMSmLd9UDllHKDm?usp=sharing](https://drive.google.com/drive/folders/1698wO-jPW8hJ28d3EpMSmLd9UDllHKDm?usp=sharing)

## üîó R√©f√©rences

- [network.tf](network.tf) - VPC et subnets
- [loadbalancer.tf](loadbalancer.tf) - ALB configuration
- [autoscaling.tf](autoscaling.tf) - ASG et scaling policies
- [launch-template.tf](launch-template.tf) - Template EC2
- [database.tf](database.tf) - RDS MySQL
- [security.tf](security.tf) - Security Groups
- [userdata.sh](userdata.sh) - Bootstrap script
